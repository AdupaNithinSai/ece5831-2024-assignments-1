{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Saving, and Testing the LeNet Model on Handwritten Digits\n",
    "\n",
    "This notebook contains the following:\n",
    "1. Train a LeNet model on the MNIST dataset.\n",
    "2. Save the trained model.\n",
    "3. Load the model back into memory.\n",
    "4. Test the model on custom handwritten digit images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train the LeNet Model and Save It\n",
    "Import the necessary libraries and create an instance of the `LeNet` class.\n",
    "The model is trained on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.7183 - accuracy: 0.7679\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1739 - accuracy: 0.9462\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1147 - accuracy: 0.9646\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0869 - accuracy: 0.9727\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0697 - accuracy: 0.9783\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0589 - accuracy: 0.9816\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0503 - accuracy: 0.9841\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0443 - accuracy: 0.9861\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0382 - accuracy: 0.9878\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0364 - accuracy: 0.9881\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0274 - accuracy: 0.9915\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0231 - accuracy: 0.9925\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0198 - accuracy: 0.9938\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0189 - accuracy: 0.9940\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0163 - accuracy: 0.9949\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0141 - accuracy: 0.9960\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Model saved to appikonda_cnn_model.keras\n"
     ]
    }
   ],
   "source": [
    "from le_net import LeNet\n",
    "\n",
    "# Initialize LeNet with desired batch size and epochs\n",
    "lenet = LeNet(batch_size=32, epochs=20)\n",
    "\n",
    "# Train the model\n",
    "lenet.train()\n",
    "\n",
    "# Save the model\n",
    "lenet.save('appikonda_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the Trained Model and our Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from le_net import LeNet\n",
    "\n",
    "# Initialize a new LeNet instance\n",
    "lenet = LeNet()\n",
    "\n",
    "# Load the previously saved model\n",
    "lenet.load('appikonda_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Dataset path containing the custom handwritten digit images\n",
    "dataset_path = \"C:/Users/saadsrin/umich/ece5831-2024-assignments/05/3/Custom_MNIST_Samples\"\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))  # Resize to match input size\n",
    "    img = img / 255.0  # Normalize\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Test the Trained Model on our Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n",
      "Fail: Image 0_0.png for digit 0 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 0_1.png for digit 0 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 0_2.png for digit 0 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 0_3.png for digit 0 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Fail: Image 0_4.png for digit 0 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 1_0.png for digit 1 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Fail: Image 1_1.png for digit 1 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 1_2.png for digit 1 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Fail: Image 1_3.png for digit 1 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 1_4.png for digit 1 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Success: Image 2_0.png for digit 2 is recognized as 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Success: Image 2_1.png for digit 2 is recognized as 2.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Success: Image 2_2.png for digit 2 is recognized as 2.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Success: Image 2_3.png for digit 2 is recognized as 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Success: Image 2_4.png for digit 2 is recognized as 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 3_0.png for digit 3 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 3_1.png for digit 3 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Fail: Image 3_2.png for digit 3 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 3_3.png for digit 3 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 3_4.png for digit 3 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 4_0.png for digit 4 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fail: Image 4_1.png for digit 4 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Fail: Image 4_2.png for digit 4 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Fail: Image 4_3.png for digit 4 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fail: Image 4_4.png for digit 4 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 5_0.png for digit 5 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 5_1.png for digit 5 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Fail: Image 5_2.png for digit 5 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fail: Image 5_3.png for digit 5 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fail: Image 5_4.png for digit 5 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Fail: Image 6_0.png for digit 6 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 6_1.png for digit 6 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fail: Image 6_2.png for digit 6 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 6_3.png for digit 6 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 6_4.png for digit 6 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Fail: Image 7_0.png for digit 7 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 7_1.png for digit 7 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Fail: Image 7_2.png for digit 7 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 7_3.png for digit 7 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 7_4.png for digit 7 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 8_0.png for digit 8 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 8_1.png for digit 8 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Fail: Image 8_2.png for digit 8 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Fail: Image 8_3.png for digit 8 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fail: Image 8_4.png for digit 8 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 9_0.png for digit 9 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Fail: Image 9_1.png for digit 9 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Fail: Image 9_2.png for digit 9 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Fail: Image 9_3.png for digit 9 but the inference result is 2.\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fail: Image 9_4.png for digit 9 but the inference result is 2.\n"
     ]
    }
   ],
   "source": [
    "# Get all folders in the dataset (each folder corresponds to a digit label)\n",
    "folders = glob.glob(os.path.join(dataset_path, \"*\"))\n",
    "\n",
    "# Iterate over each folder (which corresponds to a digit label)\n",
    "for digit_folder in folders:\n",
    "    digit_label = os.path.basename(os.path.normpath(digit_folder))[-1]  # Extract digit label from folder name\n",
    "    \n",
    "    # Iterate over all images in the folder\n",
    "    for img_file in glob.glob(os.path.join(digit_folder, \"*.png\")):        \n",
    "        # Load and preprocess the image\n",
    "        img = load_image(img_file)\n",
    "        \n",
    "        # Get the image file name (e.g., \"1_3.png\")\n",
    "        image_file_name = os.path.basename(img_file)\n",
    "        \n",
    "        # Make prediction using the trained model\n",
    "        prediction = lenet.predict([img])  # Predict for the current image\n",
    "        predicted_label = prediction[0] if prediction is not None else None # Get the predicted label\n",
    "                     \n",
    "        # Print success/failure message\n",
    "        if predicted_label == int(digit_label):\n",
    "            print(f\"Success: Image {image_file_name} for digit {digit_label} is recognized as {predicted_label}.\")\n",
    "        else:\n",
    "            print(f\"Fail: Image {image_file_name} for digit {digit_label} but the inference result is {predicted_label}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
